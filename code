"""
Credit Card Fraud Detection - GitHub-ready script
-----------------------------------------------
Files created by running this script:
 - models/fraud_pipeline.joblib   # trained pipeline (vectorizer + scaler + model)
 - artifacts/eda_plots/            # EDA plots (png)
 - reports/metrics_report.txt      # evaluation metrics & threshold analysis

Usage:
 1. Place the dataset `creditcard.csv` in the same folder as this script OR provide --data PATH
 2. pip install -r requirements.txt (see below)
 3. python credit_card_fraud_detection.py --data creditcard.csv --sampling smote --model xgb

Command-line options:
  --data      Path to creditcard.csv (default: creditcard.csv)
  --sampling  one of: none, undersample, oversample, smote (default: smote)
  --model     one of: rf, xgb (default: xgb)
  --save      Whether to save artifacts and model (default: True)

Requirements (put in requirements.txt):
 pandas
 numpy
 scikit-learn
 matplotlib
 seaborn
 xgboost
 imbalanced-learn
 joblib

"""

import os
import argparse
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (precision_score, recall_score, f1_score, roc_auc_score,
                             precision_recall_curve, confusion_matrix, classification_report)
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

import joblib
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except Exception:
    XGBOOST_AVAILABLE = False


def ensure_dirs(base_path: Path):
    (base_path / 'models').mkdir(parents=True, exist_ok=True)
    (base_path / 'artifacts' / 'eda_plots').mkdir(parents=True, exist_ok=True)
    (base_path / 'reports').mkdir(parents=True, exist_ok=True)


def load_data(path: str):
    df = pd.read_csv(path)
    return df


def basic_eda(df: pd.DataFrame, out_dir: Path):
    """Run basic EDA and save plots to out_dir (artifacts/eda_plots)."""
    plots_dir = out_dir / 'artifacts' / 'eda_plots'
    plots_dir.mkdir(parents=True, exist_ok=True)

    # Class imbalance
    counts = df['Class'].value_counts()
    print('Class distribution:')
    print(counts)

    plt.figure(figsize=(6,4))
    sns.barplot(x=counts.index, y=counts.values)
    plt.title('Class distribution (0: legit, 1: fraud)')
    plt.xlabel('Class')
    plt.ylabel('Count')
    plt.tight_layout()
    plt.savefig(plots_dir / 'class_distribution.png')
    plt.close()

    # Amount distribution (overall and by class)
    plt.figure(figsize=(8,5))
    sns.histplot(df['Amount'], bins=50)
    plt.title('Transaction Amount Distribution')
    plt.tight_layout()
    plt.savefig(plots_dir / 'amount_distribution.png')
    plt.close()

    plt.figure(figsize=(8,5))
    sns.boxplot(x='Class', y='Amount', data=df)
    plt.title('Amount by Class (boxplot)')
    plt.tight_layout()
    plt.savefig(plots_dir / 'amount_by_class_boxplot.png')
    plt.close()

    # Time feature distribution
    if 'Time' in df.columns:
        plt.figure(figsize=(8,5))
        sns.histplot(df['Time'], bins=50)
        plt.title('Transaction Time Distribution (seconds)')
        plt.tight_layout()
        plt.savefig(plots_dir / 'time_distribution.png')
        plt.close()

    # Correlations heatmap (sampled to speed up)
    corr = df.sample(min(5000, len(df))).corr()
    plt.figure(figsize=(12,10))
    sns.heatmap(corr, cmap='coolwarm', annot=False', fmt='.2f')
    plt.title('Correlation matrix (sample)')
    plt.tight_layout()
    plt.savefig(plots_dir / 'correlation_matrix.png')
    plt.close()

    # Print basic stats
    desc = df.describe().T
    desc.to_csv(out_dir / 'reports' / 'basic_stats.csv')
    print('EDA artifacts saved to', plots_dir)


def preprocess_and_split(df: pd.DataFrame, test_size=0.2, random_state=42):
    X = df.drop('Class', axis=1)
    y = df['Class']

    # Scale Amount and Time (if present) â€” other V1..V28 are already PCA'ed in common datasets
    numeric_features = []
    for col in ['Amount', 'Time']:
        if col in X.columns:
            numeric_features.append(col)

    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=test_size, random_state=random_state)

    # Fit scaler on training numeric features only
    if numeric_features:
        scaler = StandardScaler()
        X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])
        X_test[numeric_features] = scaler.transform(X_test[numeric_features])

    return X_train, X_test, y_train, y_test, numeric_features


def resample(X_train, y_train, method='smote', random_state=42):
    if method == 'none':
        return X_train, y_train
    elif method == 'undersample':
        rus = RandomUnderSampler(random_state=random_state)
        X_res, y_res = rus.fit_resample(X_train, y_train)
        return X_res, y_res
    elif method == 'oversample':
        ros = RandomOverSampler(random_state=random_state)
        X_res, y_res = ros.fit_resample(X_train, y_train)
        return X_res, y_res
    elif method == 'smote':
        sm = SMOTE(random_state=random_state)
        X_res, y_res = sm.fit_resample(X_train, y_train)
        return X_res, y_res
    else:
        raise ValueError('Unknown resampling method: ' + str(method))


def train_model(X_train, y_train, model_name='xgb'):
    if model_name == 'rf':
        model = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)
        param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [None, 10, 20]
        }
    elif model_name == 'xgb':
        if not XGBOOST_AVAILABLE:
            raise RuntimeError('xgboost not available in environment. Install xgboost or use --model rf')
        model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1, random_state=42)
        param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [3, 6]
        }
    else:
        raise ValueError('Unsupported model: ' + str(model_name))

    grid = GridSearchCV(model, param_grid, scoring='roc_auc', cv=3, n_jobs=-1, verbose=0)
    grid.fit(X_train, y_train)
    best = grid.best_estimator_
    print('Best params:', grid.best_params_)
    return best


def evaluate_model(model, X_test, y_test, out_dir: Path):
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:,1]

    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc = roc_auc_score(y_test, y_proba)

    report = classification_report(y_test, y_pred, digits=4)
    cm = confusion_matrix(y_test, y_pred)

    # Save metrics
    out_file = out_dir / 'reports' / 'metrics_report.txt'
    with open(out_file, 'w') as f:
        f.write('Precision: {:.4f}\n'.format(prec))
        f.write('Recall: {:.4f}\n'.format(rec))
        f.write('F1: {:.4f}\n'.format(f1))
        f.write('ROC AUC: {:.4f}\n\n'.format(roc))
        f.write('Classification report:\n')
        f.write(report)
        f.write('\nConfusion matrix:\n')
        f.write(str(cm))

    # Precision-Recall curve and threshold analysis
    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)
    plt.figure()
    plt.plot(recall, precision)
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall curve')
    plt.tight_layout()
    plt.savefig(out_dir / 'artifacts' / 'eda_plots' / 'precision_recall_curve.png')
    plt.close()

    # Save ROC curve
    from sklearn.metrics import roc_curve
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    plt.figure()
    plt.plot(fpr, tpr)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC curve')
    plt.tight_layout()
    plt.savefig(out_dir / 'artifacts' / 'eda_plots' / 'roc_curve.png')
    plt.close()

    print('\nEvaluation metrics saved to', out_file)
    print(report)
    return {'precision': prec, 'recall': rec, 'f1': f1, 'roc_auc': roc}


def save_pipeline(model, numeric_features, out_dir: Path):
    # We create a small pipeline to remember numeric scaler steps (if needed) and the model
    # Note: In this dataset we've already scaled numeric features in preprocess step. If you prefer
    # to build a pipeline that includes scaling, do so here.
    pipeline = {
        'model': model,
        'numeric_features': numeric_features
    }
    joblib.dump(pipeline, out_dir / 'models' / 'fraud_pipeline.joblib')
    print('Saved model pipeline to', out_dir / 'models' / 'fraud_pipeline.joblib')


def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument('--data', type=str, default='creditcard.csv')
    p.add_argument('--sampling', type=str, choices=['none','undersample','oversample','smote'], default='smote')
    p.add_argument('--model', type=str, choices=['rf','xgb'], default='xgb')
    p.add_argument('--save', type=bool, default=True)
    return p.parse_args()


def main():
    args = parse_args()
    base = Path('.')
    ensure_dirs(base)

    print('Loading data from', args.data)
    df = load_data(args.data)

    print('\nRunning basic EDA...')
    basic_eda(df, base)

    print('\nPreprocessing and splitting...')
    X_train, X_test, y_train, y_test, numeric_features = preprocess_and_split(df)
    print('Train class distribution:', y_train.value_counts().to_dict())

    print('\nResampling with method =', args.sampling)
    X_res, y_res = resample(X_train, y_train, method=args.sampling)
    print('After resampling train class distribution:', pd.Series(y_res).value_counts().to_dict())

    print('\nTraining model:', args.model)
    model = train_model(X_res, y_res, model_name=args.model)

    print('\nEvaluating model on holdout test set...')
    metrics = evaluate_model(model, X_test, y_test, base)

    if args.save:
        save_pipeline(model, numeric_features, base)

    print('\nDone.')


if __name__ == '__main__':
    main()
